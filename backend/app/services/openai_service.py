# 23062025

from openai import AsyncOpenAI
from typing import List, Dict, Any
import json
import asyncio
from datetime import datetime
import logging
from ..core.config import settings

logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
    
    async def analyze_moderator_performance(
        self,
        messages: List[Dict[str, Any]],
        prompt: str,
        moderators: List[str] = None,
        group_name: str = "Unknown"
    ) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–≤ —á–µ—Ä–µ–∑ OpenAI
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –≥—Ä—É–ø–ø—ã
            prompt: –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            moderators: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            group_name: –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ
        """
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_data = self._prepare_analysis_data(messages, moderators)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            system_prompt = self._build_system_prompt()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            user_prompt = self._build_user_prompt(
                analysis_data, prompt, group_name, moderators
            )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
            response = await self.client.chat.completions.create(
                model="gpt-4.1-2025-04-14",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=8000
            )
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            result = self._parse_openai_response(response.choices[0].message.content)


            if 'main_issues' in result and result['main_issues']:
                result['main_issues'] = self._filter_significant_issues(
                    result['main_issues'], 
                    len(messages),
                    min_percentage=7.0
                )

            logger.info(f"Successfully analyzed {len(messages)} messages for group {group_name}")
            return result
            
        except Exception as e:
            logger.error(f"Error in OpenAI analysis: {str(e)}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self._get_fallback_result()
    
    def _prepare_analysis_data(self, messages: List[Dict[str, Any]], moderators: List[str]) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–≤ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
        moderator_messages = []
        user_messages = []
        
        for msg in messages:
            sender_username = msg.get('sender', {}).get('username', '')
            is_moderator = any(mod.strip('@') in sender_username for mod in moderators) if moderators else False
            
            message_data = {
                'id': msg['message_id'],
                'text': msg['text'][:500],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
                'date': msg['date'],
                'is_reply': msg['is_reply'],
                'has_media': msg['has_media']
            }
            
            if is_moderator:
                moderator_messages.append(message_data)
            else:
                user_messages.append(message_data)
        
        return {
            'moderator_messages': moderator_messages[:20],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            'user_messages': user_messages[:30],
            'total_messages': len(messages),
            'moderator_count': len(moderator_messages),
            'conversation_threads': self._identify_threads(messages)
        }
    
    def _identify_threads(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ø–æ—á–µ–∫ –¥–∏–∞–ª–æ–≥–æ–≤"""
        threads = []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ reply_to_message_id
        for msg in messages[:10]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
            if msg['is_reply'] and msg['reply_to_message_id']:
                # –ò—â–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                original_msg = next((m for m in messages if m['message_id'] == msg['reply_to_message_id']), None)
                if original_msg:
                    threads.append({
                        'original': {
                            'text': original_msg['text'][:200],
                            'date': original_msg['date']
                        },
                        'reply': {
                            'text': msg['text'][:200],
                            'date': msg['date']
                        }
                    })
        
        return threads[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 —Ü–µ–ø–æ—á–µ–∫
    
    def _build_system_prompt(self) -> str:
        """–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–≤"""
        return """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π –≤ –æ–Ω–ª–∞–π–Ω-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. 
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ—Ü–µ–Ω–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏.

        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:
        1. –°–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        2. –ö–∞—á–µ—Å—Ç–≤–æ –∏ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤
        3. –¢–æ–Ω –æ–±—â–µ–Ω–∏—è (–¥—Ä—É–∂–µ–ª—é–±–Ω–æ—Å—Ç—å, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º)
        4. –†–µ—à–µ–Ω–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –∏ –ø—Ä–æ–±–ª–µ–º
        5. –°–æ–±–ª—é–¥–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª —Å–æ–æ–±—â–µ—Å—Ç–≤–∞

        –í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {
            "summary": {
                "sentiment_score": number (0-100),
                "response_time_avg": number (–º–∏–Ω—É—Ç—ã),
                "resolved_issues": number,
                "satisfaction_score": number (0-100),
                "engagement_rate": number (0-100)
            },
            "moderator_metrics": {
                "response_time": {"avg": number, "min": number, "max": number},
                "sentiment": {"positive": number, "neutral": number, "negative": number},
                "performance": {"effectiveness": number, "helpfulness": number, "clarity": number}
            },
            "key_topics": [string],
            "recommendations": [string]
        }"""
    
    def _build_user_prompt(self, data: Dict[str, Any], user_prompt: str, group_name: str, moderators: List[str]) -> str:
        """–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        
        prompt = f"""
        –ì–†–£–ü–ü–ê: {group_name}
        –ú–û–î–ï–†–ê–¢–û–†–´ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê: {', '.join(moderators) if moderators else '–í—Å–µ'}
        
        –ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
        {user_prompt}
        
        –î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
        - –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {data['total_messages']}
        - –°–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–≤: {data['moderator_count']}
        - –¶–µ–ø–æ—á–µ–∫ –¥–∏–∞–ª–æ–≥–æ–≤: {len(data['conversation_threads'])}
        
        –°–û–û–ë–©–ï–ù–ò–Ø –ú–û–î–ï–†–ê–¢–û–†–û–í:
        """
        
        for i, msg in enumerate(data['moderator_messages'][:10]):
            prompt += f"\n{i+1}. [{msg['date']}] {msg['text']}"
        
        if data['conversation_threads']:
            prompt += "\n\n–ü–†–ò–ú–ï–†–´ –î–ò–ê–õ–û–ì–û–í:"
            for i, thread in enumerate(data['conversation_threads']):
                prompt += f"\n\n–î–∏–∞–ª–æ–≥ {i+1}:"
                prompt += f"\n–í–æ–ø—Ä–æ—Å: {thread['original']['text']}"
                prompt += f"\n–û—Ç–≤–µ—Ç: {thread['reply']['text']}"
        
        prompt += f"\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."
        
        return prompt
    
    def _parse_openai_response(self, response_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI"""
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx != 0:
                json_str = response_text[start_idx:end_idx]
                result = json.loads(json_str)
                
                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                if self._validate_result_structure(result):
                    return result
            
            # –ï—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fallback
            logger.warning("Failed to parse OpenAI response, using fallback")
            return self._get_fallback_result()
            
        except Exception as e:
            logger.error(f"Error parsing OpenAI response: {e}")
            return self._get_fallback_result()
    
    def _validate_result_structure(self, result: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        required_keys = ['summary', 'moderator_metrics', 'key_topics', 'recommendations']
        return all(key in result for key in required_keys)
    
    def _get_fallback_result(self) -> Dict[str, Any]:
        """Fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏"""
        return {
            "summary": {
                "sentiment_score": 75,
                "response_time_avg": 5.0,
                "resolved_issues": 10,
                "satisfaction_score": 80,
                "engagement_rate": 70
            },
            "moderator_metrics": {
                "response_time": {"avg": 5.0, "min": 1.0, "max": 15.0},
                "sentiment": {"positive": 60, "neutral": 30, "negative": 10},
                "performance": {"effectiveness": 75, "helpfulness": 80, "clarity": 70}
            },
            "key_topics": ["support", "general discussion", "questions"],
            "recommendations": [
                "–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏",
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ–∑–∂–µ"
            ]
        }
    
    async def analyze_community_sentiment(
        self,
        messages: List[Dict[str, Any]],
        prompt: str = None,
        group_name: str = "Unknown"
    ) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –∂–∏—Ç–µ–ª–µ–π –∏ –ø—Ä–æ–±–ª–µ–º –ñ–ö–• —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –≥—Ä—É–ø–ø—ã
            prompt: –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            group_name: –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ —Å related_messages
        """
        try:
            logger.info(f"üè† Starting community sentiment analysis for group: {group_name}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if not messages:
                logger.warning("‚ùå No messages provided for community analysis")
                return self._get_community_fallback_result()
            
            # –û–ë–ù–û–í–õ–ï–ù–ù–´–ô —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∂–∏—Ç–µ–ª–µ–π –ñ–ö–•
            system_prompt = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –≤ –∂–∏–ª—ã—Ö –∫–æ–º–ø–ª–µ–∫—Å–∞—Ö –∏ —Ä–∞–π–æ–Ω–∞—Ö.

        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏—è –∂–∏—Ç–µ–ª–µ–π –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è:
                
        1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ –∂–∞–ª–æ–±—ã
        2. –ö–∞—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç—ã —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π –∏ –∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã—Ö —Å–ª—É–∂–±  
        3. –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∂–∏—Ç–µ–ª–µ–π
        4. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—è–º
        5. –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∑–æ–Ω—ã (–ø–æ–¥—ä–µ–∑–¥—ã, –¥–≤–æ—Ä—ã, –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞)

        –í–ê–ñ–ù–û: –î–ª—è –∫–∞–∂–¥–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –ø—Ä–æ–±–ª–µ–º—ã —É–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–µ–ª–∏ –∫ —ç—Ç–æ–º—É –≤—ã–≤–æ–¥—É.

        –í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –°–¢–†–û–ì–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
        {
            "sentiment_summary": {
                "overall_mood": "–Ω–µ–¥–æ–≤–æ–ª—å–Ω—ã|–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ|–¥–æ–≤–æ–ª—å–Ω—ã",
                "satisfaction_score": number (0-100),
                "complaint_level": "–Ω–∏–∑–∫–∏–π|—Å—Ä–µ–¥–Ω–∏–π|–≤—ã—Å–æ–∫–∏–π"
            },
            "main_issues": [
                {
                    "category": "–ñ–ö–•|–î–≤–æ—Ä|–ü–æ–¥—ä–µ–∑–¥|–ü–∞—Ä–∫–æ–≤–∫–∞|–®—É–º|–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", 
                    "issue": "–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã", 
                    "frequency": number,
                    "related_messages": [
                        {
                            "text": "–ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è",
                            "date": "2025-06-20T14:30:00",
                            "author": "–∏–º—è –∞–≤—Ç–æ—Ä–∞ –∏–ª–∏ null"
                        }
                    ]
                }
            ],
            "service_quality": {
                "—É–ø—Ä–∞–≤–ª—è—é—â–∞—è_–∫–æ–º–ø–∞–Ω–∏—è": number (0-100),
                "–∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã–µ_—Å–ª—É–∂–±—ã": number (0-100), 
                "—É–±–æ—Ä–∫–∞": number (0-100),
                "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": number (0-100)
            },
            "improvement_suggestions": [string],
            "key_topics": [string],
            "urgent_issues": [
                {
                    "issue": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–±–ª–µ–º—ã",
                    "related_messages": [
                        {
                            "text": "—Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è",
                            "date": "2025-06-20T14:30:00", 
                            "author": "–∏–º—è –∞–≤—Ç–æ—Ä–∞ –∏–ª–∏ null"
                        }
                    ]
                }
            ]
        }"""
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏–π (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤)
            message_texts = []
            for msg in messages:  # –ú–∞–∫—Å–∏–º—É–º 100 —Å–æ–æ–±—â–µ–Ω–∏–π
                if msg.get('text') and len(msg['text'].strip()) > 5:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
                    author = None
                    if msg.get('user_info') and msg['user_info']:
                        first_name = msg['user_info'].get('first_name', '')
                        last_name = msg['user_info'].get('last_name', '')
                        if first_name:
                            author = f"{first_name} {last_name[0] if last_name else ''}."
                    
                    message_texts.append({
                        'text': msg['text'][:500],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
                        'date': msg.get('date', ''),
                        'author': author
                    })
            
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            if not prompt or not prompt.strip():
                prompt = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∂–∏—Ç–µ–ª–µ–π –∏ –≤—ã—è–≤–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ –∂–∏–ª–æ–º –∫–æ–º–ø–ª–µ–∫—Å–µ"
                
            user_prompt = f"""
    –ì–†–£–ü–ü–ê: {group_name}
    –ó–ê–î–ê–ß–ê: {prompt}

    –°–û–û–ë–©–ï–ù–ò–Ø –ñ–ò–¢–ï–õ–ï–ô ({len(message_texts)} —à—Ç.):
    """
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è (–º–∞–∫—Å–∏–º—É–º 30 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤)
            for i, msg in enumerate(message_texts[:30]):
                author_info = f" –æ—Ç {msg['author']}" if msg['author'] else ""
                user_prompt += f"\n{i+1}. [{msg['date']}]{author_info}: {msg['text']}"
            
            if len(message_texts) > 30:
                user_prompt += f"\n... –∏ –µ—â–µ {len(message_texts) - 30} —Å–æ–æ–±—â–µ–Ω–∏–π"
            
            user_prompt += """

    –í–ê–ñ–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò:
    1. –î–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ–±–ª–µ–º—ã –≤ main_issues —É–∫–∞–∂–∏ –í–°–ï —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–µ–ª–∏ –∫ —ç—Ç–æ–º—É –≤—ã–≤–æ–¥—É
    2. –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–±–ª–µ–º—ã –≤ urgent_issues —Ç–∞–∫–∂–µ —É–∫–∞–∂–∏ related_messages  
    3. –í–∫–ª—é—á–∞–π –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, —Ç–æ—á–Ω—É—é –¥–∞—Ç—É –∏ –∞–≤—Ç–æ—Ä–∞ (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–µ–Ω)
    4. –ï—Å–ª–∏ –æ–¥–∏–Ω –∞–≤—Ç–æ—Ä —É–ø–æ–º–∏–Ω–∞–ª –ø—Ä–æ–±–ª–µ–º—É –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ - –≤–∫–ª—é—á–∞–π –≤—Å–µ –µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    5. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ –ø—Ä–æ–±–ª–µ–º—ã –∂–∏—Ç–µ–ª–µ–π —Å–æ–≥–ª–∞—Å–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""
            
            logger.info("üì§ Sending community analysis request to OpenAI...")
            
            # –ó–∞–ø—Ä–æ—Å –∫ OpenAI —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            response = await asyncio.wait_for(
                self.client.chat.completions.create(
                    model="gpt-4.1-2025-04-14",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=8000 # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è related_messages
                ),
                timeout=240.0
            )
            
            logger.info("‚úÖ Received community analysis response from OpenAI")
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            result = self._parse_community_response(response.choices[0].message.content)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é 7% –∫ main_issues
            if 'main_issues' in result and result['main_issues']:
                result['main_issues'] = self._filter_significant_issues(
                    result['main_issues'], 
                    len(messages),
                    min_percentage=7.0
                )
            
            logger.info("‚úÖ Community sentiment analysis completed successfully")
            return result
            
        except asyncio.TimeoutError:
            logger.error("‚è∞ OpenAI request timed out for community analysis")
            return self._get_community_fallback_result()
        except Exception as e:
            logger.error(f"üí• Error in community sentiment analysis: {str(e)}")
            return self._get_community_fallback_result()
        

    def _get_community_fallback_result(self) -> Dict[str, Any]:
        """Fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ —Å related_messages"""
        return {
            "sentiment_summary": {
                "overall_mood": "–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                "satisfaction_score": 0,
                "complaint_level": "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
            },
            "main_issues": [
                {
                    "category": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è", 
                    "issue": "–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", 
                    "frequency": 1,
                    "related_messages": [
                        {
                            "text": "–ê–Ω–∞–ª–∏–∑ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç",
                            "date": datetime.now().isoformat(),
                            "author": "–°–∏—Å—Ç–µ–º–∞"
                        }
                    ]
                }
            ],
            "service_quality": {
                "—É–ø—Ä–∞–≤–ª—è—é—â–∞—è_–∫–æ–º–ø–∞–Ω–∏—è": 0,
                "–∫–æ–º–º—É–Ω–∞–ª—å–Ω—ã–µ_—Å–ª—É–∂–±—ã": 0,
                "—É–±–æ—Ä–∫–∞": 0,
                "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å": 0
            },
            "improvement_suggestions": ["–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∞–Ω–∞–ª–∏–∑ –ø–æ–∑–∂–µ"],
            "key_topics": ["—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞"],
            "urgent_issues": [
                {
                    "issue": "–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞",
                    "related_messages": [
                        {
                            "text": "–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                            "date": datetime.now().isoformat(),
                            "author": "–°–∏—Å—Ç–µ–º–∞"
                        }
                    ]
                }
            ]
        }


    def _validate_community_structure(self, result: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ —Å related_messages"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–ª—é—á–∏
            required_keys = ['sentiment_summary', 'main_issues', 'service_quality', 'improvement_suggestions', 'key_topics', 'urgent_issues']
            
            if not all(key in result for key in required_keys):
                logger.warning(f"‚ùå Missing required keys in community analysis. Expected: {required_keys}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É sentiment_summary
            sentiment_summary = result.get('sentiment_summary', {})
            sentiment_required = ['overall_mood', 'satisfaction_score', 'complaint_level']
            if not all(key in sentiment_summary for key in sentiment_required):
                logger.warning(f"‚ùå Invalid sentiment_summary structure")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ main_issues —ç—Ç–æ —Å–ø–∏—Å–æ–∫
            main_issues = result.get('main_issues', [])
            if not isinstance(main_issues, list):
                logger.warning("‚ùå main_issues should be a list")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∂–¥–æ–π –ø—Ä–æ–±–ª–µ–º—ã –≤ main_issues
            for issue in main_issues:
                if not isinstance(issue, dict):
                    logger.warning("‚ùå Each main issue should be a dictionary")
                    return False
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                issue_required = ['category', 'issue', 'frequency']
                if not all(key in issue for key in issue_required):
                    logger.warning(f"‚ùå Issue missing required fields: {issue_required}")
                    return False
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º related_messages (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –µ—Å–ª–∏ –µ—Å—Ç—å - –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º)
                if 'related_messages' in issue:
                    if not isinstance(issue['related_messages'], list):
                        logger.warning("‚ùå related_messages should be a list")
                        return False
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                    for msg in issue['related_messages']:
                        if not isinstance(msg, dict):
                            logger.warning("‚ùå Each related message should be a dictionary")
                            return False
                        
                        msg_required = ['text', 'date']
                        if not all(key in msg for key in msg_required):
                            logger.warning(f"‚ùå Related message missing required fields: {msg_required}")
                            return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É urgent_issues
            urgent_issues = result.get('urgent_issues', [])
            if not isinstance(urgent_issues, list):
                logger.warning("‚ùå urgent_issues should be a list")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∂–¥–æ–π —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–±–ª–µ–º—ã
            for urgent in urgent_issues:
                if isinstance(urgent, str):
                    # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∏, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    continue
                elif isinstance(urgent, dict):
                    # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç - —Å related_messages
                    if 'issue' not in urgent:
                        logger.warning("‚ùå Urgent issue missing 'issue' field")
                        return False
                    
                    if 'related_messages' in urgent:
                        if not isinstance(urgent['related_messages'], list):
                            logger.warning("‚ùå urgent issue related_messages should be a list")
                            return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É service_quality
            service_quality = result.get('service_quality', {})
            if not isinstance(service_quality, dict):
                logger.warning("‚ùå service_quality should be a dictionary")
                return False
            
            logger.info("‚úÖ Community analysis result structure is valid")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error validating community analysis structure: {e}")
            return False
    
    def _parse_community_response(self, response_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞"""
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx != 0:
                json_str = response_text[start_idx:end_idx]
                result = json.loads(json_str)
                
                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞
                if self._validate_community_structure(result):
                    logger.info("Successfully parsed community analysis response")
                    return result
            
            logger.warning("Failed to parse community analysis response, using fallback")
            return self._get_community_fallback_result()
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error in community analysis response: {e}")
            return self._get_community_fallback_result()
        except Exception as e:
            logger.error(f"Error parsing community analysis response: {e}")
            return self._get_community_fallback_result()

    def _validate_community_structure(self, result: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–ª—é—á–∏
            required_keys = ['sentiment_summary', 'main_issues', 'service_quality', 'improvement_suggestions', 'key_topics', 'urgent_issues']
            
            if not all(key in result for key in required_keys):
                logger.warning(f"Missing required keys in community analysis result. Expected: {required_keys}, Got: {list(result.keys())}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É sentiment_summary
            sentiment_summary = result.get('sentiment_summary', {})
            sentiment_required = ['overall_mood', 'satisfaction_score', 'complaint_level']
            if not all(key in sentiment_summary for key in sentiment_required):
                logger.warning(f"Invalid sentiment_summary structure. Expected: {sentiment_required}, Got: {list(sentiment_summary.keys())}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ main_issues —ç—Ç–æ —Å–ø–∏—Å–æ–∫
            if not isinstance(result.get('main_issues', []), list):
                logger.warning("main_issues should be a list")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É service_quality
            service_quality = result.get('service_quality', {})
            if not isinstance(service_quality, dict):
                logger.warning("service_quality should be a dictionary")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è —ç—Ç–æ —Å–ø–∏—Å–∫–∏
            list_fields = ['improvement_suggestions', 'key_topics', 'urgent_issues']
            for field in list_fields:
                if not isinstance(result.get(field, []), list):
                    logger.warning(f"{field} should be a list")
                    return False
            
            logger.info("Community analysis result structure is valid")
            return True
            
        except Exception as e:
            logger.error(f"Error validating community analysis structure: {e}")
            return False
        
    def _filter_significant_issues(
        self, 
        issues: List[Dict[str, Any]], 
        total_messages: int, 
        min_percentage: float = 7.0
    ) -> List[Dict[str, Any]]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–æ–±–ª–µ–º –ø–æ –ø—Ä–∞–≤–∏–ª—É –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞
        
        Args:
            issues: –°–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º –æ—Ç OpenAI
            total_messages: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            min_percentage: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∑–Ω–∞—á–∏–º–æ–π –ø—Ä–æ–±–ª–µ–º—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 7%)
            
        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–æ–±–ª–µ–º
        """
        if not issues or total_messages == 0:
            return issues
        
        filtered_issues = []
        
        logger.info(f"üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º: —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {min_percentage}% –æ—Ç {total_messages} —Å–æ–æ–±—â–µ–Ω–∏–π")
        
        for issue in issues:
            # –°—á–∏—Ç–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ related_messages
            related_messages = issue.get('related_messages', [])
            related_count = len(related_messages)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç
            percentage = (related_count / total_messages) * 100 if total_messages > 0 else 0
            
            logger.info(f"üìä –ü—Ä–æ–±–ª–µ–º–∞ '{issue.get('issue', 'Unknown')}': {related_count}/{total_messages} = {percentage:.1f}%")
            
            if percentage >= min_percentage:
                filtered_issues.append(issue)
                logger.info(f"‚úÖ –û—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º—É (>= {min_percentage}%)")
            else:
                logger.info(f"‚ùå –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º—É –∫–∞–∫ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—É—é (< {min_percentage}%)")
        
        logger.info(f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_issues)} –∏–∑ {len(issues)} –ø—Ä–æ–±–ª–µ–º –æ—Å—Ç–∞–≤–ª–µ–Ω–æ")
        
        return filtered_issues
    
    async def analyze_posts_comments(
        self,
        comments: List[Dict[str, Any]],
        posts_info: List[Dict[str, Any]],
        prompt: str = None,
        group_name: str = "Unknown"
    ) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –ø–æ—Å—Ç–∞–º —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —Ä–µ–∞–∫—Ü–∏–∏ –∏ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        
        Args:
            comments: –°–ø–∏—Å–æ–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –ø–æ—Å—Ç–∞–º
            posts_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å—Ç–∞—Ö
            prompt: –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            group_name: –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –ø–æ—Å—Ç–∞–º
        """
        try:
            logger.info(f"üîó Starting posts comments analysis for group: {group_name}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if not comments:
                logger.warning("‚ùå No comments provided for posts analysis")
                return self._get_posts_fallback_result()
            
            # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –ø–æ—Å—Ç–∞–º
            system_prompt = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –º–Ω–µ–Ω–∏—è –∏ —Ä–µ–∞–∫—Ü–∏–π –Ω–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.

    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –ø–æ—Å—Ç–∞–º –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è:

    1. –û–±—â–∏–µ —Ä–µ–∞–∫—Ü–∏–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (–ø–æ–¥–¥–µ—Ä–∂–∫–∞/–∫—Ä–∏—Ç–∏–∫–∞/–Ω–µ–π—Ç—Ä–∞–ª–∏—Ç–µ—Ç)
    2. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö  
    3. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ç–æ—Ä–æ–≤
    4. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω —Ä–µ–∞–∫—Ü–∏–π
    5. –ù–∞–∏–±–æ–ª–µ–µ –æ–±—Å—É–∂–¥–∞–µ–º—ã–µ –∞—Å–ø–µ–∫—Ç—ã –ø–æ—Å—Ç–æ–≤

    –í–ê–ñ–ù–û: –î–ª—è –∫–∞–∂–¥–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Ç–µ–º—ã –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —É–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–µ–ª–∏ –∫ —ç—Ç–æ–º—É –≤—ã–≤–æ–¥—É.

    –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:

    {
    "sentiment_summary": {
        "overall_mood": "–æ–±—â–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ (–ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ/–Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ)",
        "satisfaction_score": —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 100,
        "complaint_level": "—É—Ä–æ–≤–µ–Ω—å –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞ (–Ω–∏–∑–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–≤—ã—Å–æ–∫–∏–π)"
    },
    "main_issues": [
        {
        "category": "–∫–∞—Ç–µ–≥–æ—Ä–∏—è –ø—Ä–æ–±–ª–µ–º—ã",
        "issue": "–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏–ª–∏ —Ç–µ–º—ã",
        "frequency": —á–∏—Å–ª–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π,
        "related_messages": [
            {
            "text": "–ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è",
            "date": "–¥–∞—Ç–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è",
            "author": "–∞–≤—Ç–æ—Ä (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–µ–Ω)",
            "post_link": "—Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç"
            }
        ]
        }
    ],
    "post_reactions": {
        "–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ": —á–∏—Å–ª–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Ä–µ–∞–∫—Ü–∏–π,
        "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ": —á–∏—Å–ª–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —Ä–µ–∞–∫—Ü–∏–π,  
        "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ": —á–∏—Å–ª–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ä–µ–∞–∫—Ü–∏–π
    },
    "improvement_suggestions": ["—Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"],
    "key_topics": ["–æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è"],
    "urgent_issues": [
        {
        "issue": "—Å—Ä–æ—á–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Ç—Ä–µ–±—É—é—â–∞—è –≤–Ω–∏–º–∞–Ω–∏—è",
        "related_messages": [
            {
            "text": "–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ–± —Å—Ä–æ—á–Ω–æ–π –ø—Ä–æ–±–ª–µ–º–µ",
            "date": "–¥–∞—Ç–∞", 
            "author": "–∞–≤—Ç–æ—Ä",
            "post_link": "—Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç"
            }
        ]
        }
    ]
    }"""

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            comment_texts = []
            for comment in comments[:50]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
                author = ""
                if comment.get('author'):
                    author_info = comment['author']
                    if author_info.get('username'):
                        author = f"@{author_info['username']}"
                    elif author_info.get('first_name'):
                        author = author_info.get('first_name', '')
                
                comment_texts.append({
                    'text': comment['text'][:500],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                    'date': comment.get('date', ''),
                    'author': author,
                    'post_link': comment.get('post_link', '')
                })
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å—Ç–∞—Ö
            posts_summary = []
            for post_info in posts_info:
                post_data = post_info.get('post_info', {})
                posts_summary.append({
                    'link': post_data.get('link', ''),
                    'message_id': post_data.get('message_id', ''),
                    'comments_count': post_info.get('comments_count', 0)
                })
            
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            if not prompt or not prompt.strip():
                prompt = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∞–∫—Ü–∏–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –ø–æ—Å—Ç–∞–º, –≤—ã—è–≤–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è"
                
            user_prompt = f"""
    –ì–†–£–ü–ü–ê: {group_name}
    –ó–ê–î–ê–ß–ê: {prompt}

    –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú–´–ï –ü–û–°–¢–´ ({len(posts_summary)} —à—Ç.):
    """
            
            for i, post in enumerate(posts_summary):
                user_prompt += f"\n{i+1}. {post['link']} ({post['comments_count']} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)"
            
            user_prompt += f"""

    –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ò –ö –ü–û–°–¢–ê–ú ({len(comment_texts)} —à—Ç.):
    """
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            for i, comment in enumerate(comment_texts):
                author_info = f" –æ—Ç {comment['author']}" if comment['author'] else ""
                post_link = f" [–ü–æ—Å—Ç: {comment['post_link']}]" if comment['post_link'] else ""
                user_prompt += f"\n{i+1}. [{comment['date']}]{author_info}{post_link}: {comment['text']}"
            
            user_prompt += """

    –í–ê–ñ–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò:
    1. –î–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ–±–ª–µ–º—ã –≤ main_issues —É–∫–∞–∂–∏ –í–°–ï –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–µ–ª–∏ –∫ —ç—Ç–æ–º—É –≤—ã–≤–æ–¥—É
    2. –î–ª—è urgent_issues —Ç–∞–∫–∂–µ —É–∫–∞–∂–∏ related_messages —Å –ø–æ–ª–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
    3. –í–∫–ª—é—á–∞–π –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è, –¥–∞—Ç—É, –∞–≤—Ç–æ—Ä–∞ –∏ —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Å—Ç
    4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–º–µ–Ω–Ω–æ —Ä–µ–∞–∫—Ü–∏–∏ –Ω–∞ –ø–æ—Å—Ç—ã, –∞ –Ω–µ –æ–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä—É–ø–ø—ã
    5. –û–ø—Ä–µ–¥–µ–ª–∏ –∫–∞–∫–∏–µ –ø–æ—Å—Ç—ã –≤—ã–∑–≤–∞–ª–∏ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –¥–∏—Å–∫—É—Å—Å–∏–π"""
            
            logger.info("üì§ Sending posts comments analysis request to OpenAI...")
            
            # –ó–∞–ø—Ä–æ—Å –∫ OpenAI —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            response = await asyncio.wait_for(
                self.client.chat.completions.create(
                    model="gpt-4.1-2025-04-14",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=8000 # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è related_messages
                ),
                timeout=240.0
            )
            
            logger.info("‚úÖ Received posts comments analysis response from OpenAI")
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            result = self._parse_posts_response(response.choices[0].message.content)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é 7% –∫ main_issues
            if 'main_issues' in result and result['main_issues']:
                result['main_issues'] = self._filter_significant_issues(
                    result['main_issues'], 
                    len(comments),
                    min_percentage=7.0
                )
            
            logger.info("‚úÖ Posts comments analysis completed successfully")
            return result
            
        except asyncio.TimeoutError:
            logger.error("‚è∞ OpenAI request timed out for posts comments analysis")
            return self._get_posts_fallback_result()
        except Exception as e:
            logger.error(f"üí• Error in posts comments analysis: {str(e)}")
            return self._get_posts_fallback_result()


    def _parse_posts_response(self, response_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –ø–æ—Å—Ç–∞–º"""
        try:
            logger.info("Parsing OpenAI response for posts analysis...")
            
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–æ–±–µ–ª—ã
            response_text = response_text.strip()
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –±–ª–æ–∫ —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
            json_str = None
            
            # –°–ø–æ—Å–æ–± 1: –ò—â–µ–º –ø–µ—Ä–≤—ã–π { –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π }
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_str = response_text[start_idx:end_idx]
            
            # –°–ø–æ—Å–æ–± 2: –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –º–µ–∂–¥—É ```json –∏ ```
            if not json_str:
                json_start = response_text.find('```json')
                if json_start != -1:
                    json_start += 7  # –¥–ª–∏–Ω–∞ '```json'
                    json_end = response_text.find('```', json_start)
                    if json_end != -1:
                        json_str = response_text[json_start:json_end].strip()
            
            # –°–ø–æ—Å–æ–± 3: –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏, –±–µ—Ä–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
            if not json_str:
                json_str = response_text
            
            # –û—á–∏—â–∞–µ–º JSON –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
            json_str = json_str.replace('\n', ' ')
            json_str = json_str.replace('\r', ' ')
            json_str = json_str.replace('\t', ' ')
            
            # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
            import re
            json_str = re.sub(r'\s+', ' ', json_str)
            
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
            result = json.loads(json_str)
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if self._validate_posts_structure(result):
                logger.info("Successfully parsed and validated posts analysis response")
                return result
            else:
                logger.warning("Parsed JSON but structure validation failed")
                return self._get_posts_fallback_result()
                
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error in posts analysis: {e}")
            logger.error(f"Problematic JSON: {json_str[:500] if 'json_str' in locals() else 'N/A'}")
            return self._get_posts_fallback_result()
            
        except Exception as e:
            logger.error(f"Unexpected error parsing posts response: {e}")
            return self._get_posts_fallback_result()


    def _validate_posts_structure(self, result: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –ø–æ—Å—Ç–∞–º"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–ª—é—á–∏
            required_keys = ['sentiment_summary', 'main_issues', 'post_reactions', 'improvement_suggestions', 'key_topics', 'urgent_issues']
            
            if not all(key in result for key in required_keys):
                logger.warning(f"Missing required keys in posts analysis result. Expected: {required_keys}, Got: {list(result.keys())}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É sentiment_summary
            sentiment_summary = result.get('sentiment_summary', {})
            sentiment_required = ['overall_mood', 'satisfaction_score', 'complaint_level']
            if not all(key in sentiment_summary for key in sentiment_required):
                logger.warning(f"Invalid sentiment_summary structure. Expected: {sentiment_required}, Got: {list(sentiment_summary.keys())}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ main_issues —ç—Ç–æ —Å–ø–∏—Å–æ–∫
            if not isinstance(result.get('main_issues', []), list):
                logger.warning("main_issues should be a list")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É post_reactions
            post_reactions = result.get('post_reactions', {})
            if not isinstance(post_reactions, dict):
                logger.warning("post_reactions should be a dictionary")
                return False
            
            logger.info("Posts comments analysis result structure is valid")
            return True
            
        except Exception as e:
            logger.error(f"Error validating posts analysis structure: {e}")
            return False


    def _get_posts_fallback_result(self) -> Dict[str, Any]:
        """Fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –ø–æ—Å—Ç–∞–º"""
        return {
            "sentiment_summary": {
                "overall_mood": "–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                "satisfaction_score": 0,
                "complaint_level": "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
            },
            "main_issues": [
                {
                    "category": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è", 
                    "issue": "–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", 
                    "frequency": 1,
                    "related_messages": [
                        {
                            "text": "–ê–Ω–∞–ª–∏–∑ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç",
                            "date": datetime.now().isoformat(),
                            "author": "–°–∏—Å—Ç–µ–º–∞",
                            "post_link": ""
                        }
                    ]
                }
            ],
            "post_reactions": {
                "–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ": 0,
                "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ": 0,
                "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ": 0
            },
            "improvement_suggestions": ["–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∞–Ω–∞–ª–∏–∑ –ø–æ–∑–∂–µ"],
            "key_topics": ["—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞"],
            "urgent_issues": [
                {
                    "issue": "–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞",
                    "related_messages": [
                        {
                            "text": "–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                            "date": datetime.now().isoformat(),
                            "author": "–°–∏—Å—Ç–µ–º–∞", 
                            "post_link": ""
                        }
                    ]
                }
            ]
        }